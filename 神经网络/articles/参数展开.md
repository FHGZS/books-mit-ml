参数展开（Unrolling Parameters）
==========

在神经网络的学习过程中，我们的工作对象面临的是一些矩阵：

$$

\Theta^{(1)},\Theta^{(2)},\Theta^{(3)},... \\
D^{(1)}, D^{(2)}, D^{(3)}, ...

$$

这对于编程里面一些的 API 是不友善的，例如 matlab 或者 octave 的 `fminunc()` 方法，[scipy](https://www.scipy.org/) 中的 `minimize` 方法等，这些方法都支持传递代价函数 $$costFunction$$，但是代价函数只支持传递**向量**作为参数，因此，我们需要先将矩阵元素平铺开为一个长向量：

matlab 中展开：

```matlab
thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]
deltaVector = [ D1(:); D2(:); D3(:) ]
```

python 中展开：

```py
import numpy as np
# ...
thetaVector = np.r_[Theta1.reshape(-1,1), Theta2.reshape(-1,1), Theta3.reshape(-1,1)]
deltaVector = np.r_[ D1.reshape(-1,1), D2.reshape(-1,1), D3.reshape(-1,1) ]
```

假定：

$$

\Theta^{(1)} \in R^{10 \times 11},\Theta^{(2)} \in R^{10 \times 11},\Theta^{(3)} \in R^{1 \times 11} \\

$$

matlab 中还原：

```matlab
Theta1 = reshape(thetaVec(1:110),10,11)
Theta2 = reshape(thetaVec(111:220),10,11)
Theta3 = reshape(thetaVec(221:231),1,11)
```

python 中还原：

```py
import numpy as np
# ...
Theta1 = thetaVec[0:110].reshape(10,11)
Theta2 = thetaVec[110:220].reshape(10,11)
Theta3 = thetaVec[220:231].reshape(1,11)
```
