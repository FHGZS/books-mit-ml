# 线性回归
## 引子
先看一个问题：
假定我们现有一大批数据，包含房屋的面积信息及对应该面积的房价的信息，如果我们能得到房屋面积与房屋价格间的关系，那么，当给定一个房屋时，我们只要知道其面积，就能大致推测出其价格了。

上面的问题还可以被转义如下：
> “OK，我具备了很多关于房屋面积及其对应售价的知识（数据），再通过一定的学习，当面对新的房屋面积时，我不再对其定价感到束手无策”。

通常，这类预测问题可以用__回归模型（regression）__进行解决，回归模型定义了__输入__与__输出__的关系，输入即现有知识，而输出则为预测。

一个预测问题在回归模型下的解决步骤为：

1. __积累知识__： 我们将储备的知识称之为*训练集Training Set*，很好理解，知识能够训练人进步
2. __学习__：学习如何预测，得到输入与输出的关系。在学习阶段，应当有合适的指导方针，江山不能仅凭热血就攻下。在这里，合适的指导方针我们称之为*Learning Algorithm*
3. __预测__：学习完成后，当接受了新的数据（输入）后，我们就能通过学习阶段获得的*对应关系*来预测输出。

学习过程往往是艰苦的，“人谁无过，过而能改，善莫大焉”，因此对我们有这两点要求：
- 有__手段__能评估我们的学习正确性
- 当学习效果不佳时，有__手段__能纠正我们的学习策略

## 线性回归
首先，我们明确几个常用的数学符号：
- __特征（feature）__：$$x_i$$， 比如，房屋的面积，卧室数量都算房屋的特征
- __特征向量（输入）__：$$x$$，一套房屋的信息就算一个特征向量，特征向量由特征组成，$$x_j(i)$$表示第$$i$$个特征向量的第$$j$$个特征。
- __输出向量__：$$y$$，$$y_i$$表示了第$$i$$个输入所对应的输出
- __假设（hypothesis）__：也称为预测函数，比如一个线性预测函数是：
$$
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\dots+\theta_nx_n=\theta^Tx
$$上面的表达式也称之为__回归方程（regression equation）__，$$\theta$$为回归系数。由于输入$$x$$是固定不变的，所以回归系数$$\theta$$将是保证我们预测准度的基石。

之前我们说到，需要某个__手段__来评估我们的学习效果，即评估各个真实值$$y_i$$与预测值$$h_\theta(x^{(i)})$$之间的误差。最常见的，我们通过*最小均方（Least Mean Square）*来计算误差：
$$ 
J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^{m}[h_\theta(x^{(i)})-y_i]^2
$$



