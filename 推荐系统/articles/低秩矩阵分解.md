低秩矩阵分解（Low Rank Matrix Factorization）
=============================

我们将用户对电影的评分表格：

| Movie/User           | Alice(1) | Bob(2) | Carol(3) | Dave(4) |
|:---------------------|:---------|:-------|:---------|:--------|
| Love at last         | 5        | 5      | 0        | 0       |
| Romance for ever     | 5        | ?      | ?        | 0       |
| Cute puppies of love | ?        | 4      | 0        | ?       |
| Nonstop car chases   | 0        | 0      | 5        | 4       |
| Swords vs. karate    | 0        | 0      | 5        | ?       |

用矩阵表示：

$$

Y =
\begin{bmatrix}
5 & 5 & 0 & 0 \\
5 & ? & ? & 0 \\
? & 4 & 0 & ? \\
0 & 0 & 5 & 4 \\
0 & 0 & 5 & 0
\end{bmatrix}

$$

我们发现，由于用户不会对所有电影都进行打分，所以该矩阵是十分稀疏的。如果我们用预测来描述这个矩阵：

$$

Predicated =
\begin{bmatrix}
(\theta^{(1)})^T x^{(1)} & (\theta^{(2)})^T x^{(1)} & \cdots & (\theta^{(n_u)})^T x^{(1)} \\
(\theta^{(1)})^T x^{(2)} & (\theta^{(2)})^T x^{(2)} & \cdots & (\theta^{(n_u)})^T x^{(2)} \\
\vdots & \vdots & \vdots & \vdots \\
(\theta^{(1)})^T x^{(n_m)} & (\theta^{(2)})^T x^{(n_m)} & \cdots & (\theta^{(n_u)})^T x^{(n_m)}
\end{bmatrix}

$$

令：

$$

X =
\begin{bmatrix}
(x^{(1)})^T \\
(x^{(2)})^T \\
\vdots \\
(x^{(n_m)})^T
\end{bmatrix},

\Theta =
\begin{bmatrix}
(\theta^{(1)})^T \\
(\theta^{(2)})^T \\
\vdots \\
(\theta^{(n_u)})^T
\end{bmatrix}

$$


即 $$X$$ 的每一行描述了一部电影的内容，$$\Theta^T$$ 的每一列描述了用户对于电影内容偏好程度，亦即，我们将原来稀疏的矩阵分解为了 $$X$$ 和 $$\Theta$$。现在预测可以写为：

$$

Predicated = X \Theta^T

$$

用这个方法求取 $$X$$ 和 $$\Theta$$，获得推荐系统需要的参数，称之为**低秩矩阵分解**，该方法不仅能在编程时直接通过向量化的手法获得参数，还通过矩阵分解节省了内存空间。
